{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras_radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "x1Zoz1yB_UlT"
   },
   "outputs": [],
   "source": [
    "# img_dir = '/Users/User/303/KT_32px/food_competition_KT_set1/train/'\n",
    "# categoris = os.listdir(img_dir)\n",
    "# nb_categoris = len(categoris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# labels = []\n",
    "# for i in range(nb_categoris) :\n",
    "#     a = glob.glob(img_dir+'/'+categoris[i]+'/*.jpg')\n",
    "#     for j in a :\n",
    "#         image=tensorflow.keras.preprocessing.image.load_img(j, color_mode='rgb')\n",
    "#         image=np.array(image)\n",
    "#         data.append(image)\n",
    "#         labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=np.array(data)\n",
    "# data=data/255.0\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('data.npy')\n",
    "#data=data/255.0\n",
    "#data[0]\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.load('labels.npy')\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1663597601047,
     "user": {
      "displayName": "79 303",
      "userId": "17202908532703153036"
     },
     "user_tz": -540
    },
    "id": "8qF7yZHaAXtK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "np.random.seed(0)\n",
    "k=5\n",
    "kf=KFold(n_splits=k,shuffle=True,random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D,MaxPooling2D,ReLU,LeakyReLU,ELU,BatchNormalization,Dropout,GlobalAveragePooling2D,Input,AveragePooling2D, Activation\n",
    "from tensorflow.keras.layers import MaxPool2D,Concatenate\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Nadam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1663598049730,
     "user": {
      "displayName": "79 303",
      "userId": "17202908532703153036"
     },
     "user_tz": -540
    },
    "id": "iXT2VxwsBBN3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "#act = tf.nn.leaky_relu\n",
    "act = tf.nn.relu\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#65í¼ Best batch32 epoch 200 adam()\n",
    "def model_fn():\n",
    "  with tf.device(\"/gpu:0\"):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation=act, kernel_initializer='he_normal', padding='same', input_shape=(128, 128, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), activation=act, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(256, (3, 3), activation=act, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), activation=act, kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(50, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1663598051214,
     "user": {
      "displayName": "79 303",
      "userId": "17202908532703153036"
     },
     "user_tz": -540
    },
    "id": "91nvoqpxBgpk",
    "outputId": "a3a88593-91ff-4978-a554-e03d5a57bb42",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 128, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2097280   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                6450      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,280,338\n",
      "Trainable params: 3,278,162\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fn().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_schedule(epoch):\n",
    "#     lr = 1e-3\n",
    "#     if epoch > 80:\n",
    "#         lr *= 0.5e-3\n",
    "#     elif epoch > 60:\n",
    "#         lr *= 1e-3\n",
    "#     elif epoch > 40:\n",
    "#         lr *= 1e-2\n",
    "#     elif epoch > 2:\n",
    "#         lr *= 1e-1\n",
    "#     print('Learning rate: ', lr)\n",
    "#     return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "#                                cooldown=0,\n",
    "#                                patience=5,\n",
    "#                                min_lr=0.5e-6)\n",
    "\n",
    "# callbacks = [lr_reducer, lr_scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ne3qM0uYCSMy",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12440\\1645387615.py:37: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(trainiterator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 30s 353ms/step - loss: 4.2410 - accuracy: 0.0599 - val_loss: 4.1252 - val_accuracy: 0.0350\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 3.1511 - accuracy: 0.1857 - val_loss: 4.4665 - val_accuracy: 0.0520\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 21s 330ms/step - loss: 2.6317 - accuracy: 0.2816 - val_loss: 4.5504 - val_accuracy: 0.0585\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 2.3273 - accuracy: 0.3470 - val_loss: 4.8075 - val_accuracy: 0.0740\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 21s 330ms/step - loss: 2.1088 - accuracy: 0.4016 - val_loss: 4.5843 - val_accuracy: 0.1145\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 1.9527 - accuracy: 0.4461 - val_loss: 3.6584 - val_accuracy: 0.1715\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 21s 330ms/step - loss: 1.8225 - accuracy: 0.4749 - val_loss: 3.1612 - val_accuracy: 0.2415\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 1.7137 - accuracy: 0.5070 - val_loss: 2.6548 - val_accuracy: 0.3195\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 1.6143 - accuracy: 0.5320 - val_loss: 2.1423 - val_accuracy: 0.4145\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 1.5315 - accuracy: 0.5496 - val_loss: 1.9948 - val_accuracy: 0.4520\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 1.4707 - accuracy: 0.5621 - val_loss: 2.1748 - val_accuracy: 0.4095\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 1.3909 - accuracy: 0.5924 - val_loss: 1.8784 - val_accuracy: 0.4850\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 1.3434 - accuracy: 0.5970 - val_loss: 1.9100 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 1.2531 - accuracy: 0.6215 - val_loss: 1.6700 - val_accuracy: 0.5105\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 1.2235 - accuracy: 0.6316 - val_loss: 1.8082 - val_accuracy: 0.5180\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 1.1542 - accuracy: 0.6556 - val_loss: 1.8714 - val_accuracy: 0.5005\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 1.1009 - accuracy: 0.6656 - val_loss: 1.6933 - val_accuracy: 0.5260\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 1.0686 - accuracy: 0.6727 - val_loss: 1.6404 - val_accuracy: 0.5650\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.9994 - accuracy: 0.6952 - val_loss: 1.6803 - val_accuracy: 0.5450\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.9478 - accuracy: 0.7081 - val_loss: 1.5448 - val_accuracy: 0.5845\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.9205 - accuracy: 0.7134 - val_loss: 1.4507 - val_accuracy: 0.5985\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.8929 - accuracy: 0.7279 - val_loss: 1.8001 - val_accuracy: 0.5075\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.8306 - accuracy: 0.7433 - val_loss: 1.6201 - val_accuracy: 0.5755\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.8184 - accuracy: 0.7499 - val_loss: 1.4294 - val_accuracy: 0.6085\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.7534 - accuracy: 0.7701 - val_loss: 1.5077 - val_accuracy: 0.5860\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.7184 - accuracy: 0.7750 - val_loss: 1.4728 - val_accuracy: 0.6060\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.6936 - accuracy: 0.7812 - val_loss: 1.3310 - val_accuracy: 0.6385\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.6663 - accuracy: 0.7885 - val_loss: 1.3519 - val_accuracy: 0.6275\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.6392 - accuracy: 0.7960 - val_loss: 1.2702 - val_accuracy: 0.6550\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.5969 - accuracy: 0.8123 - val_loss: 1.4611 - val_accuracy: 0.6140\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 21s 339ms/step - loss: 0.5783 - accuracy: 0.8185 - val_loss: 1.3648 - val_accuracy: 0.6425\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 21s 340ms/step - loss: 0.5509 - accuracy: 0.8236 - val_loss: 1.4880 - val_accuracy: 0.6170\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 0.5461 - accuracy: 0.8241 - val_loss: 1.4329 - val_accuracy: 0.6300\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 0.5039 - accuracy: 0.8472 - val_loss: 1.2298 - val_accuracy: 0.6710\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.4891 - accuracy: 0.8414 - val_loss: 1.4227 - val_accuracy: 0.6395\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.4667 - accuracy: 0.8499 - val_loss: 1.2937 - val_accuracy: 0.6670\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.4206 - accuracy: 0.8671 - val_loss: 1.4084 - val_accuracy: 0.6530\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.4109 - accuracy: 0.8680 - val_loss: 1.3070 - val_accuracy: 0.6675\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.3934 - accuracy: 0.8736 - val_loss: 1.2593 - val_accuracy: 0.6805\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.3791 - accuracy: 0.8760 - val_loss: 1.2615 - val_accuracy: 0.6780\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 21s 339ms/step - loss: 0.3800 - accuracy: 0.8786 - val_loss: 1.3458 - val_accuracy: 0.6690\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.3542 - accuracy: 0.8884 - val_loss: 1.2910 - val_accuracy: 0.6810\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.3353 - accuracy: 0.8932 - val_loss: 1.4038 - val_accuracy: 0.6770\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.3617 - accuracy: 0.8795 - val_loss: 1.4336 - val_accuracy: 0.6605\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.3291 - accuracy: 0.8945 - val_loss: 1.2713 - val_accuracy: 0.6885\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 22s 342ms/step - loss: 0.3146 - accuracy: 0.8950 - val_loss: 1.1969 - val_accuracy: 0.7020\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.3067 - accuracy: 0.8991 - val_loss: 1.3677 - val_accuracy: 0.6740\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.3010 - accuracy: 0.9007 - val_loss: 1.3248 - val_accuracy: 0.6840\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.2868 - accuracy: 0.9109 - val_loss: 1.5211 - val_accuracy: 0.6540\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.2773 - accuracy: 0.9095 - val_loss: 1.4431 - val_accuracy: 0.6665\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.2733 - accuracy: 0.9125 - val_loss: 1.3646 - val_accuracy: 0.6780\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.2914 - accuracy: 0.9038 - val_loss: 1.3305 - val_accuracy: 0.6895\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.2552 - accuracy: 0.9133 - val_loss: 1.3611 - val_accuracy: 0.6970\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.2481 - accuracy: 0.9211 - val_loss: 1.3711 - val_accuracy: 0.6910\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.2357 - accuracy: 0.9200 - val_loss: 1.3677 - val_accuracy: 0.6855\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 21s 338ms/step - loss: 0.2250 - accuracy: 0.9279 - val_loss: 1.3451 - val_accuracy: 0.6940\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 333ms/step - loss: 0.2227 - accuracy: 0.9294 - val_loss: 1.3177 - val_accuracy: 0.6910\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 21s 340ms/step - loss: 0.2234 - accuracy: 0.9265 - val_loss: 1.3834 - val_accuracy: 0.6745\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.2184 - accuracy: 0.9285 - val_loss: 1.2868 - val_accuracy: 0.6990\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.2122 - accuracy: 0.9316 - val_loss: 1.2118 - val_accuracy: 0.7080\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 21s 338ms/step - loss: 0.1901 - accuracy: 0.9390 - val_loss: 1.4143 - val_accuracy: 0.6900\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.1939 - accuracy: 0.9377 - val_loss: 1.3928 - val_accuracy: 0.6885\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 0.1991 - accuracy: 0.9352 - val_loss: 1.5131 - val_accuracy: 0.6820\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.1830 - accuracy: 0.9413 - val_loss: 1.3510 - val_accuracy: 0.6980\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.1852 - accuracy: 0.9388 - val_loss: 1.4783 - val_accuracy: 0.6805\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.1722 - accuracy: 0.9442 - val_loss: 1.4213 - val_accuracy: 0.6855\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.1717 - accuracy: 0.9442 - val_loss: 1.4339 - val_accuracy: 0.6825\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.1828 - accuracy: 0.9405 - val_loss: 1.3188 - val_accuracy: 0.7040\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.2016 - accuracy: 0.9333 - val_loss: 1.3904 - val_accuracy: 0.7030\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.1749 - accuracy: 0.9435 - val_loss: 1.5100 - val_accuracy: 0.6820\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 21s 339ms/step - loss: 0.1816 - accuracy: 0.9425 - val_loss: 1.4701 - val_accuracy: 0.6810\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.1672 - accuracy: 0.9459 - val_loss: 1.5177 - val_accuracy: 0.6800\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.1913 - accuracy: 0.9390 - val_loss: 1.4451 - val_accuracy: 0.6980\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.1609 - accuracy: 0.9466 - val_loss: 1.3607 - val_accuracy: 0.7100\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.1669 - accuracy: 0.9427 - val_loss: 1.4366 - val_accuracy: 0.6985\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 21s 339ms/step - loss: 0.1528 - accuracy: 0.9486 - val_loss: 1.4138 - val_accuracy: 0.6850\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.1453 - accuracy: 0.9511 - val_loss: 1.3707 - val_accuracy: 0.7140\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.1545 - accuracy: 0.9473 - val_loss: 1.3749 - val_accuracy: 0.7105\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.1470 - accuracy: 0.9510 - val_loss: 1.5006 - val_accuracy: 0.6945\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.1501 - accuracy: 0.9500 - val_loss: 1.3931 - val_accuracy: 0.6990\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 21s 340ms/step - loss: 0.1473 - accuracy: 0.9555 - val_loss: 1.4226 - val_accuracy: 0.6970\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.1347 - accuracy: 0.9549 - val_loss: 1.5497 - val_accuracy: 0.6725\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.1547 - accuracy: 0.9465 - val_loss: 1.4552 - val_accuracy: 0.7085\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.1499 - accuracy: 0.9523 - val_loss: 1.4504 - val_accuracy: 0.6980\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.1603 - accuracy: 0.9473 - val_loss: 1.4694 - val_accuracy: 0.7010\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.1434 - accuracy: 0.9521 - val_loss: 1.4161 - val_accuracy: 0.6955\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.1592 - accuracy: 0.9454 - val_loss: 1.4891 - val_accuracy: 0.6840\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.1734 - accuracy: 0.9415 - val_loss: 1.5025 - val_accuracy: 0.7045\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.1314 - accuracy: 0.9561 - val_loss: 1.4915 - val_accuracy: 0.7065\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.1402 - accuracy: 0.9554 - val_loss: 1.5754 - val_accuracy: 0.6910\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 21s 338ms/step - loss: 0.1321 - accuracy: 0.9560 - val_loss: 1.4084 - val_accuracy: 0.7175\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.1286 - accuracy: 0.9571 - val_loss: 1.4477 - val_accuracy: 0.7035\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.1368 - accuracy: 0.9550 - val_loss: 1.3382 - val_accuracy: 0.7240\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.1502 - accuracy: 0.9489 - val_loss: 1.4900 - val_accuracy: 0.6900\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.1194 - accuracy: 0.9614 - val_loss: 1.5587 - val_accuracy: 0.6920\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.1306 - accuracy: 0.9575 - val_loss: 1.4470 - val_accuracy: 0.7110\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 21s 339ms/step - loss: 0.1307 - accuracy: 0.9572 - val_loss: 1.4446 - val_accuracy: 0.7040\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.1249 - accuracy: 0.9564 - val_loss: 1.5013 - val_accuracy: 0.6890\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.1208 - accuracy: 0.9590 - val_loss: 1.4062 - val_accuracy: 0.7125\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.1193 - accuracy: 0.9601 - val_loss: 1.4169 - val_accuracy: 0.7220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12440\\1645387615.py:42: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  scores = model.evaluate_generator(testiterator, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 258ms/step - loss: 1.4273 - accuracy: 0.7120\n",
      "Score for fold 1: loss of 1.4273148775100708; accuracy of 71.20000123977661%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 26s 339ms/step - loss: 4.2046 - accuracy: 0.0615 - val_loss: 4.3424 - val_accuracy: 0.0340\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 3.1439 - accuracy: 0.1791 - val_loss: 5.7864 - val_accuracy: 0.0335\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 2.6494 - accuracy: 0.2690 - val_loss: 5.6554 - val_accuracy: 0.0490\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 2.3231 - accuracy: 0.3491 - val_loss: 4.8182 - val_accuracy: 0.0720\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 21s 338ms/step - loss: 2.0858 - accuracy: 0.4042 - val_loss: 4.5818 - val_accuracy: 0.0750\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 1.9206 - accuracy: 0.4494 - val_loss: 3.4523 - val_accuracy: 0.1865\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 1.8086 - accuracy: 0.4715 - val_loss: 3.1939 - val_accuracy: 0.2175\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 1.6998 - accuracy: 0.5015 - val_loss: 2.4379 - val_accuracy: 0.3490\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 1.5974 - accuracy: 0.5278 - val_loss: 2.3742 - val_accuracy: 0.3625\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 1.5287 - accuracy: 0.5494 - val_loss: 2.1383 - val_accuracy: 0.4115\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 1.4850 - accuracy: 0.5554 - val_loss: 2.0251 - val_accuracy: 0.4420\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 1.4206 - accuracy: 0.5689 - val_loss: 1.8368 - val_accuracy: 0.4890\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 1.3484 - accuracy: 0.6001 - val_loss: 1.7020 - val_accuracy: 0.5075\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 1.2893 - accuracy: 0.6109 - val_loss: 1.7993 - val_accuracy: 0.5015\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 1.2268 - accuracy: 0.6269 - val_loss: 1.6659 - val_accuracy: 0.5155\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 1.1749 - accuracy: 0.6436 - val_loss: 1.7876 - val_accuracy: 0.4810\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 1.1300 - accuracy: 0.6562 - val_loss: 1.7396 - val_accuracy: 0.5165\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 1.0692 - accuracy: 0.6699 - val_loss: 1.5020 - val_accuracy: 0.5710\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 1.0257 - accuracy: 0.6856 - val_loss: 1.5897 - val_accuracy: 0.5320\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 1.0013 - accuracy: 0.6896 - val_loss: 1.3596 - val_accuracy: 0.5900\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.9489 - accuracy: 0.7088 - val_loss: 1.4132 - val_accuracy: 0.6005\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.9231 - accuracy: 0.7237 - val_loss: 1.3702 - val_accuracy: 0.5930\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.8661 - accuracy: 0.7341 - val_loss: 1.4206 - val_accuracy: 0.5995\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.8161 - accuracy: 0.7473 - val_loss: 1.3254 - val_accuracy: 0.6220\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 0.7907 - accuracy: 0.7546 - val_loss: 1.2051 - val_accuracy: 0.6490\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.7645 - accuracy: 0.7638 - val_loss: 1.2911 - val_accuracy: 0.6290\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.7092 - accuracy: 0.7803 - val_loss: 1.5535 - val_accuracy: 0.5735\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.7058 - accuracy: 0.7805 - val_loss: 1.4050 - val_accuracy: 0.5985\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.6553 - accuracy: 0.7903 - val_loss: 1.2781 - val_accuracy: 0.6415\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.6283 - accuracy: 0.8031 - val_loss: 1.2266 - val_accuracy: 0.6555\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.6148 - accuracy: 0.8083 - val_loss: 1.3735 - val_accuracy: 0.6165\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.5820 - accuracy: 0.8215 - val_loss: 1.4096 - val_accuracy: 0.6225\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.5526 - accuracy: 0.8248 - val_loss: 1.3025 - val_accuracy: 0.6420\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.5142 - accuracy: 0.8400 - val_loss: 1.3749 - val_accuracy: 0.6275\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 21s 336ms/step - loss: 0.4944 - accuracy: 0.8401 - val_loss: 1.2344 - val_accuracy: 0.6585\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.4767 - accuracy: 0.8501 - val_loss: 1.2868 - val_accuracy: 0.6645\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.4517 - accuracy: 0.8593 - val_loss: 1.1686 - val_accuracy: 0.6885\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.4574 - accuracy: 0.8516 - val_loss: 1.2083 - val_accuracy: 0.6820\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.4048 - accuracy: 0.8734 - val_loss: 1.1889 - val_accuracy: 0.6700\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 0.3863 - accuracy: 0.8767 - val_loss: 1.2237 - val_accuracy: 0.6880\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.3840 - accuracy: 0.8756 - val_loss: 1.1846 - val_accuracy: 0.6725\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.3641 - accuracy: 0.8819 - val_loss: 1.4191 - val_accuracy: 0.6380\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.3481 - accuracy: 0.8938 - val_loss: 1.2398 - val_accuracy: 0.6775\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.3333 - accuracy: 0.8941 - val_loss: 1.1900 - val_accuracy: 0.6850\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.3430 - accuracy: 0.8885 - val_loss: 1.2548 - val_accuracy: 0.6730\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.3248 - accuracy: 0.8953 - val_loss: 1.3312 - val_accuracy: 0.6700\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.3288 - accuracy: 0.8935 - val_loss: 1.2384 - val_accuracy: 0.6860\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.2993 - accuracy: 0.9022 - val_loss: 1.2585 - val_accuracy: 0.6885\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.2971 - accuracy: 0.9072 - val_loss: 1.3759 - val_accuracy: 0.6655\n",
      "Epoch 50/100\n",
      " 5/63 [=>............................] - ETA: 15s - loss: 0.3101 - accuracy: 0.8984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 336ms/step - loss: 0.4483 - accuracy: 0.8571 - val_loss: 1.3638 - val_accuracy: 0.6405\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 21s 341ms/step - loss: 0.4373 - accuracy: 0.8596 - val_loss: 1.2307 - val_accuracy: 0.6780\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.4146 - accuracy: 0.8686 - val_loss: 1.1726 - val_accuracy: 0.6800\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 0.3893 - accuracy: 0.8725 - val_loss: 1.4314 - val_accuracy: 0.6365\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.3855 - accuracy: 0.8765 - val_loss: 1.3533 - val_accuracy: 0.6640\n",
      "Epoch 42/100\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.8792"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining for fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Fit data to model\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainiterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtestiterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Generate generalization metrics\u001b[39;00m\n\u001b[0;32m     42\u001b[0m scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate_generator(testiterator, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2260\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2249\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m \n\u001b[0;32m   2251\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2252\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2255\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2256\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2258\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2259\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 2260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "pat = 20\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "fold_no = 1\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    trainGenerator = ImageDataGenerator(rescale=1/255., horizontal_flip=True,\n",
    "                        rotation_range = 15, shear_range=0.2)\n",
    "    trainiterator = trainGenerator.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "    testGenerator = ImageDataGenerator(rescale=1/255., horizontal_flip=True,\n",
    "                        rotation_range = 15, shear_range=0.2)\n",
    "    testiterator = testGenerator.flow(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "    model = model_fn()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RAdam(), metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit_generator(trainiterator,\n",
    "                  epochs=EPOCHS,\n",
    "                  validation_data= testiterator, verbose=1)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate_generator(testiterator, verbose=1)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZ5e96-iTOqk"
   },
   "outputs": [],
   "source": [
    "accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1662995232078,
     "user": {
      "displayName": "79 303",
      "userId": "17202908532703153036"
     },
     "user_tz": -540
    },
    "id": "c5vE7GAkHLXS",
    "outputId": "4a0ae0b5-2706-42bf-aacf-80e1d7b5bc48"
   },
   "outputs": [],
   "source": [
    "# ë³µìž¡í•œ ëª¨ë¸ epoch 50\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcYs-7vpSaNr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1662997607880,
     "user": {
      "displayName": "79 303",
      "userId": "17202908532703153036"
     },
     "user_tz": -540
    },
    "id": "2VmexrReF0DN",
    "outputId": "3d031da7-09a6-4c22-8c17-68194e23a66e"
   },
   "outputs": [],
   "source": [
    "np.mean(accuracy_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1662995232079,
     "user": {
      "displayName": "79 303",
      "userId": "17202908532703153036"
     },
     "user_tz": -540
    },
    "id": "I8xFg8AaDQ5g",
    "outputId": "b5e4375b-abb7-4a99-bfe4-4fac6c9a50c6"
   },
   "outputs": [],
   "source": [
    "accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eu5LD-yKK_UI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMNn1e/+3IGeEGfxqN6sDXm",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "",
   "provenance": [
    {
     "file_id": "1oj_Wt6vGL62hwN_-nB1iV5n-iamBt05C",
     "timestamp": 1662994504366
    },
    {
     "file_id": "1Um1M-0rxRZb3WSUSwlx4878pfS_GUfyD",
     "timestamp": 1662993365188
    }
   ],
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
